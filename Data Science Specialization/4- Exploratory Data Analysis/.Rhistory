swirl()
?read.csv
read.csv(path2csv, stringsAsFactors = FALSE)
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
tbl_df
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran,)
select(cran,1)
select(cran,-(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
a
a <- 1
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, r_version !is.na())
filter(cran, r_version== !is.na())
filter(cran, !na(r_version))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
desc(ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(country, desc(r_version), ip_id)
arrange(cran2, country, desc(r_version), ip_id)
select(cran, ip_id, package, size)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size / 2^10)
mutate(cran3, size-mb = size / 2^20, size_gb = size / 2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size / 2^10)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = 1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf)")
rm("mydf")
cran
?group_by
group_by(cran, by_package)
group_by(cran, variable)
cran
by_package <- group_by(cran, package)
by_package
mean(by_package)
summarize(by_package, mean(size))
swirl()
swirl()
swirl()
swirl()
library(swirl)
swirl()
reset()
swirl()
swirl()
swirl()
#Load libraries
library(plyr)
library(dplyr)
#library(data.table)
#library(Hmisc)
#Get Store Sales Forecast from SAS forecast
salef = read.csv("StoreSalesForecast.csv", header=TRUE, stringsAsFactors=FALSE)
#Get Actual Sales from finance team (excluding Pharmacy sales)
actsales = read.csv("2014 15 Actual Sales ex Rx.csv", header=TRUE, stringsAsFactors = FALSE)
#####Pull volume driver actuals data from Teradata#####
vold <-
dbGetQuery(TeraInConn,
"
select top 100
a.location as store,
a.cal_wk_beg_d as cal_wk_beg_d,
a.vd as drvr,
b.acct_wk_i as acct_wk,
b.pryr_ad_wk_i as one_yr_adshft_wk,
d.pryr_ad_wk_i as two_yr_adshft_wk,
b.acct_mo_i as acct_mo,
b.acct_mo_wk_i as acct_mo_wk,
b.acct_yr_i as acct_yr,
b.pryr_ad_yr_i as one_yr_adshft_yr,
d.pryr_ad_yr_i as two_yr_adshft_yr,
c.co_loc_clos_d as clos_d,
sum(a.actual_units) as drvr_amt
from
DLBIS_MYTIME.VOL_DRV_ACT as a
left join
PRODRPT_V.CAL_WK_DIM_V as b
on a.cal_wk_beg_d = b.cal_wk_beg_d
left join
PRODRPT_V.CO_LOC_DIM_V  as c
on a.location = c.co_loc_frmt_shrt_n
left join
PRODRPT_V.CAL_WK_DIM_V as d
on b.pryr_acct_wk_beg_d = d.cal_wk_beg_d
where
c.co_loc_type_c = 'STR'
group by
a.location,
a.cal_wk_beg_d,
a.vd,
b.acct_wk_i,
b.pryr_ad_wk_i,
b.acct_mo_i,
b.acct_mo_wk_i,
b.acct_yr_i,
b.pryr_ad_yr_i,
c.co_loc_clos_d,
d.pryr_ad_wk_i,
d.pryr_ad_yr_i,
d.cal_wk_beg_d
"
)
#Load libraries
library(plyr)
library(dplyr)
#library(data.table)
#library(Hmisc)
#Get Store Sales Forecast from SAS forecast
salef = read.csv("StoreSalesForecast.csv", header=TRUE, stringsAsFactors=FALSE)
current <- read.csv("\\\\nicsrv10\\tts\\LaborstandardsAndBudgeting\\SepNodeLvlFCST.csv")
View(current)
current <- subset(current, DRVR_TYPE_C == 'V', select=c('Loc', 'DRVR_NAME', 'NODE_NAME', 'WK_BEG_D',
'DRVR_NODE_FORECAST'))
colnames(current) <- c('str_i', 'drvr', 'drvr_node', 'KRONOS', 'WK_BEG_D', 'DRVR_NODE_FORECAST', 'DRVR_TYPE_C')
current <- subset(current, DRVR_TYPE_C == 'V', select=c('Loc', 'DRVR_NAME', 'NODE_NAME', 'WK_BEG_D',
'DRVR_NODE_FORECAST'))
current <- subset(current, DRVR_TYPE_C == 'V', select=c('str_i', 'drvr', 'drvr_node', 'cal_wk_beg_d',
'node_forecast'))
View(current)
colnames(current) <- c('str_i', 'drvr', 'drvr_node', 'KRONOS', 'cal_wk_beg_d', 'node_forecast', 'DRVR_TYPE_C')
current <- subset(current, DRVR_TYPE_C == 'V', select=c('str_i', 'drvr', 'drvr_node', 'cal_wk_beg_d',
'node_forecast'))
View(current)
sz <- read.csv("H:\\FactorForecasting\\Factors\\augSep2016NodePercent.csv")
sz$CAL_WK_BEG_D <-  as.Date(sz$CAL_WK_BEG_D)
sz$loc2 <- as.numeric(substr(sz$Location,2,5))
View(sz)
colnames(sz)
colnames(sz) <- c('loc', 'drvr', 'drvr_node', 'pct_of_total_drvr', 'cal_wk_beg_d', 'str_i')
node.pcts <- subset(sz, select=c('cal_wk_beg_d', 'str_i', 'drvr', 'drvr_node', 'pct_of_total_drvr'))
View(node.pcts)
szfacs <- read.csv("H:\\FactorForecasting\\Factors\\StoreDriverWeekRatioSZ_12Sep2016.csv")
head(szfacs)
View(current)
View(current)
szfacs$cal_wk_beg_d <-  as.Date(szfacs$cal_wk_beg_d)
szfacs$cal_wk_beg_d <-  as.Date(szfacs$CAL_WK_BEG_D)
head(szfacs)
TeradataDriver <- JDBC(
"com.teradata.jdbc.TeraDriver",
"\\\\ttcfile04\\storeops\\StoreBusinessIntelligence\\JavaJars\\Teradata\\terajdbc4.jar;\\\\ttcfile04\\storeops\\StoreBusinessIntelligence\\JavaJars\\Teradata\\tdgssconfig.jar",
identifier.quote = "`"
)
TeradataConnect <-
dbConnect(
TeradataDriver,
"jdbc:teradata://tdproda/LOGMECH=LDAP",
as.character(subset(
read.csv("H:\\SZCredentials.csv"), Database == "EDW"
)$username),
as.character(subset(
read.csv("H:\\SZCredentials.csv"), Database == "EDW"
)$password)
)
salef <-
dbGetQuery(
TeradataConnect,
"
select
ACCT_YR as acct_yr,
STORE as str_i,
acct_wk_i as acct_wk,
FCST_AMT_ACTL as fcst_amt
from (
select
acct_yr_i as ACCT_YR,
acct_mo_i as ACCT_MO,
acct_mo_wk_i as ACCT_MO_WK,
co_loc.co_loc_clos_d as CLOS_D,
co_loc.co_loc_ref_i  as STORE,
co_loc.co_loc_n as co_loc_n,
acct_wk_i as acct_wk_i,
sum(actl_fcst_sls_a) as FCST_AMT_ACTL
from
prodrpt_v.dly_str_sls_pyrl_mtrc fcast
inner join
prodrpt_v.cal_date_dim cal
on fcast.mtrc_rpt_d= cal.greg_d
inner join
prodrpt_v.co_loc_dim_v co_loc
on fcast.brck_mrtr_str_i = co_loc.co_loc_i
where
mtrc_rpt_d>='2016-01-31'
and FIN_RPT_CO_REF_I = 4
group by
1,2,3,4,5,6,7
) X
where
(FCST_AMT_ACTL <> 0)
and upper(co_loc_n) not like '%PHARMACY%'
"
)
salef$fcst_amt <- as.numeric(gsub( "[$,]", "",as.character(salef$fcst_amt)))
View(salef)
# Read in driver actuals
node.data <-
dbGetQuery(
TeradataConnect,
"
select
acct_yr,
acct_wk,
drvr,
drvr_node,
str_i,
cal_wk_beg_d,
drvact_ty
from
DLBIS_SLPFCAST.AD_SHIFT_DRV_NODE_ACTS_MEANS drv
inner join prodrpt_v.brck_mrtr_str_dim_v str on drv.str_i = str.co_loc_ref_i
where
acct_yr = 2016
"
)
View(node.data)
node.data$cal_wk_beg_d <-  as.Date(node.data$cal_wk_beg_d)
node.data.subset <- subset(node.data, cal_wk_beg_d >='2016-08-28' & cal_wk_beg_d <= '2016-09-25')
View(node.data.subset)
colnames(szfacs)
colnames(salef)
factor.forecast <- merge(szfacs, salef, by=c'acct_wk', 'acct_yr', 'str_i')
factor.forecast <- merge(szfacs, salef, by=c('acct_wk', 'acct_yr', 'str_i'))
View(factor.forecast)
factor.forecast$driver.forecast <- factor.forecast$mean_ratio * factor.forecast$fcst_amt
View(factor.forecast)
colnames(factor.forecast)
colnames(node.pcts)
colnames(factor.forecast)
colnames(node.data)
factor.forecast.node.acts <- merge(factor.forecast, node.data,
by=c('acct_yr', 'acct_wk', 'str_i', 'drvr'))
View(factor.forecast.node.acts)
View(factor.forecast.node.acts)
str(factor.forecast.node.acts)
factor.forecast.node.acts <- subset(factor.forecast.node.acts, cal_wk_beg_d >='2016-08-28' & cal_wk_beg_d <= '2016-09-25')
View(factor.forecast.node.acts)
colnames(factor.forecast.node.acts)
colnames(node.pcts)
by=c('cal_wk_beg_d', 'str_i', 'drvr', 'drvr_node'))
factor.forecast.node.acts.pct <- merge(factor.forecast.node.acts, node.pcts,
by=c('cal_wk_beg_d', 'str_i', 'drvr', 'drvr_node'))
View(factor.forecast.node.acts.pct)
factor.forecast.node.acts.pct$node.forecast <- factor.forecast.node.acts.pct$pct_of_total_drvr*factor.forecast.node.acts.pct$driver.forecast
View(factor.forecast.node.acts.pct)
options(scipen = 999)
View(factor.forecast.node.acts.pct)
View(factor.forecast.node.acts.pct)
colnames(factor.forecast.node.acts.pct)
factor.forecast.node.acts.pct <- mutate(factor.forecast.node.acts.pct, PredDiff = abs(drvact_ty - node.forecast) / drvact_ty)
#Load libraries
library(RJDBC)
library(plyr)
library(dplyr)
options(scipen = 999)
factor.forecast.node.acts.pct <- mutate(factor.forecast.node.acts.pct, PredDiff = abs(drvact_ty - node.forecast) / drvact_ty)
View(factor.forecast.node.acts.pct)
factor.forecast.node.acts.pct <- subset(factor.forecast.node.acts.pct, acct_wk < 33)
View(factor.forecast.node.acts.pct)
factor.forecast.node.acts.pct <- subset(factor.forecast.node.acts.pct, acct_wk < 32)
View(factor.forecast.node.acts.pct)
factor.forecast.node.acts.pct <- subset(factor.forecast.node.acts.pct, acct_wk < 31)
View(factor.forecast.node.acts.pct)
View(factor.forecast.node.acts.pct)
factor.forecast.node.acts.pct <- merge(factor.forecast.node.acts, node.pcts,
by=c('cal_wk_beg_d', 'str_i', 'drvr', 'drvr_node'))
factor.forecast.node.acts.pct$node.forecast <- factor.forecast.node.acts.pct$pct_of_total_drvr*factor.forecast.node.acts.pct$driver.forecast
factor.forecast.node.acts.pct <- mutate(factor.forecast.node.acts.pct, PredDiff = abs(drvact_ty - node.forecast) / drvact_ty)
View(factor.forecast.node.acts.pct)
factor.forecast.node.acts.pct <- subset(factor.forecast.node.acts.pct, acct_wk ==31 | acct_wk == 32)
View(factor.forecast.node.acts.pct)
View(factor.forecast.node.acts.pct)
factor.forecast.node.acts.pct.zeroTY <- subset(factor.forecast.node.acts.pct, drvact_ty == 0)
factor.forecast.node.acts.pct.NonzeroTY <- subset(factor.forecast.node.acts.pct, drvact_ty != 0)
View(factor.forecast.node.acts.pct.zeroTY)
View(factor.forecast.node.acts.pct.NonzeroTY)
colnames(node_forecast)
colnames(compare.against.current)
colnames(current)
colnames(factor.forecast.node.acts.pct)
compare.against.current <- merge(factor.forecast.node.acts, current, by=c('cal_wk_beg_d', 'str_i', 'drvr', 'drvr_node'))
View(compare.against.current)
compare.against.current <- merge(factor.forecast.node.acts.pct, current, by=c('cal_wk_beg_d', 'str_i', 'drvr', 'drvr_node'))
View(compare.against.current)
compare.against.current <- merge(factor.forecast.node.acts.pct, current, by=c('cal_wk_beg_d', 'str_i', 'drvr', 'drvr_node'))
compare.against.current <- mutate(compare.against.current, SZPredDiff = abs(drvact_ty - node.forecast) / drvact_ty)
compare.against.current <- mutate(compare.against.current, CurrPredDiff = abs(drvact_ty - node_forecast) / drvact_ty)
View(compare.against.current)
colnames(compare.against.current)
compare.against.current <- subset(compare.against.current, select=c('acct_yr', 'acct_wk', 'str_i', 'drvr', 'drvr_node', 'SZPredDiff', 'CurrPredDiff'))
View(compare.against.current)
write.csv(compare.against.current, "H:\\FactorForecasting\\Testing\\node_level_comp_13sep2016.csv", row.names = FALSE)
View(compare.against.current)
test <- subset(compare.against.current, drvr_node == 'BAKECAKE')
View(test)
mean(test$SZPredDiff)
View(compare.against.current)
compare.against.current <- merge(factor.forecast.node.acts.pct, current, by=c('cal_wk_beg_d', 'str_i', 'drvr', 'drvr_node'))
View(compare.against.current)
View(compare.against.current)
colnames(compare.against.current)
compare.against.current.units <- mutate(compare.against.current.units, SZUnitsDiff = abs(drvact_ty - node.forecast))
compare.against.current.units <- mutate(compare.against.current, SZUnitsDiff = abs(drvact_ty - node.forecast))
View(compare.against.current.units)
compare.against.current.units <- mutate(compare.against.current, CurrUnitsDiff = abs(drvact_ty - node_forecast))
View(compare.against.current.units)
colnames(compare.against.current.units)
compare.against.current.units <- mutate(compare.against.current, SZUnitsDiff = abs(drvact_ty - node.forecast))
compare.against.current.units <- mutate(compare.against.current, CurrUnitsDiff = abs(drvact_ty - node_forecast))
colnames(compare.against.current.units)
compare.against.current.units <- mutate(compare.against.current, SZUnitsDiff = abs(drvact_ty - node.forecast))
View(compare.against.current.units)
compare.against.current.units <- mutate(compare.against.current.units, CurrUnitsDiff = abs(drvact_ty - node_forecast))
colnames(compare.against.current.units)
compare.against.current.units <- subset(compare.against.current.units, select=c('acct_yr', 'acct_wk', 'str_i', 'drvr', 'drvr_node', 'SZUnitsDiff', 'CurrUnitsDiff'))
View(compare.against.current.units)
compare.against.current.units <- mutate(compare.against.current, SZUnitsDiff = drvact_ty - node.forecast)
compare.against.current.units <- mutate(compare.against.current.units, CurrUnitsDiff = drvact_ty - node_forecast)
compare.against.current.units <- subset(compare.against.current.units, select=c('acct_yr', 'acct_wk', 'str_i', 'drvr', 'drvr_node', 'SZUnitsDiff', 'CurrUnitsDiff'))
View(compare.against.current.units)
write.csv(compare.against.current, "H:\\FactorForecasting\\Testing\\pct_error_node_level_comp_13sep2016.csv", row.names = FALSE)
write.csv(compare.against.current.pcterror, "H:\\FactorForecasting\\Testing\\pct_error_node_level_comp_13sep2016.csv", row.names = FALSE)
write.csv(compare.against.current.units, "H:\\FactorForecasting\\Testing\\drvr_units_node_level_comp_13sep2016.csv", row.names = FALSE)
compare.against.current.pcterror <- mutate(compare.against.current, SZPredDiff = abs(drvact_ty - node.forecast) / drvact_ty)
compare.against.current.pcterror <- mutate(compare.against.current.pcterror, CurrPredDiff = abs(drvact_ty - node_forecast) / drvact_ty)
compare.against.current.pcterror <- subset(compare.against.current.pcterror, select=c('acct_yr', 'acct_wk', 'str_i', 'drvr', 'drvr_node', 'SZPredDiff', 'CurrPredDiff'))
write.csv(compare.against.current.pcterror, "H:\\FactorForecasting\\Testing\\pct_error_node_level_comp_13sep2016.csv", row.names = FALSE)
write.csv(compare.against.current.pcterror, "H:\\FactorForecasting\\Testing\\pct_error_node_level_comp_13sep2016.csv", row.names = FALSE)
write.csv(compare.against.current.units, "H:\\FactorForecasting\\Testing\\drvr_units_node_level_comp_13sep2016.csv", row.names = FALSE)
compare.against.current.pcterror <- mutate(compare.against.current, SZPredDiff = abs(drvact_ty - node.forecast) / drvact_ty)
compare.against.current.pcterror <- mutate(compare.against.current.pcterror, CurrPredDiff = abs(drvact_ty - node_forecast) / drvact_ty)
compare.against.current.pcterror <- subset(compare.against.current.pcterror, select=c('acct_yr', 'acct_wk', 'str_i', 'drvr', 'drvr_node', 'drvact_ty', 'SZPredDiff', 'CurrPredDiff'))
compare.against.current.units <- mutate(compare.against.current, SZUnitsDiff = drvact_ty - node.forecast)
compare.against.current.units <- mutate(compare.against.current.units, CurrUnitsDiff = drvact_ty - node_forecast)
compare.against.current.units <- subset(compare.against.current.units, select=c('acct_yr', 'acct_wk', 'str_i', 'drvr', 'drvr_node',  'drvact_ty', 'SZUnitsDiff', 'CurrUnitsDiff'))
write.csv(compare.against.current.pcterror, "H:\\FactorForecasting\\Testing\\pct_error_node_level_comp_13sep2016.csv", row.names = FALSE)
write.csv(compare.against.current.units, "H:\\FactorForecasting\\Testing\\drvr_units_node_level_comp_13sep2016.csv", row.names = FALSE)
compare.against.current.units <- subset(compare.against.current.units, select=c('acct_yr', 'acct_wk', 'str_i', 'drvr', 'drvr_node',  'drvact_ty', 'node.forecast', 'node_forecast'))
compare.against.current.units <- mutate(compare.against.current, SZUnitsDiff = drvact_ty - node.forecast)
compare.against.current.units <- mutate(compare.against.current.units, CurrUnitsDiff = drvact_ty - node_forecast)
compare.against.current.units <- subset(compare.against.current.units, select=c('acct_yr', 'acct_wk', 'str_i', 'drvr', 'drvr_node',  'drvact_ty', 'node.forecast', 'node_forecast'))
write.csv(compare.against.current.units, "H:\\FactorForecasting\\Testing\\drvr_units_node_level_comp_13sep2016.csv", row.names = FALSE)
result<-wilcox.test(bmark_pct~type,data=weekly_pre, alternative = 'two.sided')
setwd("\\\\lif-core-smbprd\\STORES_BI\\Food Transformation\\Grocery Op Model")
install.packages("RHive")
library(RHive)
#install.packages("ggplot2")
library(ggplot2)
setwd("H:/Coursera/Data Science Specialization/4- Exploratory Data Analysis")
# Check to see if DataForPeerAssessment.zip already exists in working directory.  If it doesn't exist already,
# pull data from Coursera webpage and load into working directory under zip file DataForPeerAssessment.zip
# If it does exist, do nothing.
if (all(
!file.exists("DataForPeerAssessment.zip"),
!dir.exists("DataForPeerAssessment"),
!file.exists("Source_Classification_Code.rds")
)) {
tryCatch({
download.file(
"https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip",
"DataForPeerAssessment.zip"
)
print("File did not exist, but was successfully downloaded from the URL.")
},
error = function(cond) {
print(
"File did not exist, but there was an error in downloading the file from the provided URL."
)
})
}
# Check to see if "DataForPeerAssessment" already exists in working directory.  If it doesn't exist already,
# zip data from DataForPeerAssessment.zip and load into working directory as "DataForPeerAssessment".
# If it does exist, remove DataForPeerAssessment.zip from working directory.
if (!dir.exists("DataForPeerAssessment")) {
tryCatch({
unzip("DataForPeerAssessment.zip")
print(
"File household_power_consumption.txt Dataset did not exist, but was successfully unzipped from DataForPeerAssessment.zip"
)
},
error = function(cond) {
print(
"File household_power_consumption.txt Dataset did not exist, and there was an error in unzipping the file."
)
})
} else {
file.remove("DataForPeerAssessment.zip")
print("FromCoursera.zip deleted since rds files were successfully created.")
}
if (file.exists("Source_Classification_Code.rds")) {
file.remove("DataForPeerAssessment.zip")
print("DataForPeerAssessment.zip deleted since rds files were successfully created.")
}
## This first line will likely take a few seconds. Be patient!
if (exists("NEI")) {
print("NEI exists")
} else {
NEI <- readRDS("summarySCC_PM25.rds")
}
if (exists("SCC")) {
print("SCC exists")
} else {
SCC <- readRDS("Source_Classification_Code.rds")
}
# Of the four types of sources indicated by the ðšðš¢ðš™ðšŽ (point, nonpoint, onroad, nonroad) variable, which of these four sources have seen decreases in emissions
# from 1999â€“2008 for Baltimore City? Which have seen increases in emissions from 1999â€“2008? Use the ggplot2 plotting system to make a plot answer this question.
NEI.subset  <- NEI[NEI$fips == "24510",]
totalByYear <- aggregate(Emissions ~ year + type, NEI.subset, sum)
png('ExData_Plotting2/plot3.png', width=1080, height=640)
plt <- ggplot(totalByYear, aes(year, Emissions, color = type))
plt <- plt +
geom_line() +
xlab("Year") +
ylab(expression('PM 2.5 emission')) +
ggtitle('PM 2.5 emission in Baltimore City, MD by source type (1999-200 -  by 3 year interval).')
print(plt)
dev.off()
#install.packages("ggplot2")
library(ggplot2)
setwd("H:/Coursera/Data Science Specialization/4- Exploratory Data Analysis")
# Check to see if DataForPeerAssessment.zip already exists in working directory.  If it doesn't exist already,
# pull data from Coursera webpage and load into working directory under zip file DataForPeerAssessment.zip
# If it does exist, do nothing.
if(all(!file.exists("DataForPeerAssessment.zip"), !dir.exists("DataForPeerAssessment"),!file.exists("Source_Classification_Code.rds"))) {
tryCatch({
download.file("https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2FNEI_data.zip", "DataForPeerAssessment.zip")
print("File did not exist, but was successfully downloaded from the URL.")
},
error = function(cond) {
print(
"File did not exist, but there was an error in downloading the file from the provided URL."
)
})
}
# Check to see if "DataForPeerAssessment" already exists in working directory.  If it doesn't exist already,
# zip data from DataForPeerAssessment.zip and load into working directory as "DataForPeerAssessment".
# If it does exist, remove DataForPeerAssessment.zip from working directory.
if (!dir.exists("DataForPeerAssessment")) {
tryCatch({
unzip("DataForPeerAssessment.zip")
print("File household_power_consumption.txt Dataset did not exist, but was successfully unzipped from DataForPeerAssessment.zip")
},
error = function(cond) {
print("File household_power_consumption.txt Dataset did not exist, and there was an error in unzipping the file.")
})
} else {
file.remove("DataForPeerAssessment.zip")
print("FromCoursera.zip deleted since rds files were successfully created.")
}
if (file.exists("Source_Classification_Code.rds")) {
file.remove("DataForPeerAssessment.zip")
print("DataForPeerAssessment.zip deleted since rds files were successfully created.")
}
## This first line will likely take a few seconds. Be patient!
if(exists("NEI")) {
print("NEI exists")
} else {
NEI <- readRDS("summarySCC_PM25.rds")
}
if(exists("SCC")) {
print("SCC exists")
} else {
SCC <- readRDS("Source_Classification_Code.rds")
}
NEISCC <- merge(NEI, SCC, by="SCC")
# Across the United States, how have emissions from coal combustion-related sources changed from 1999â€“2008?
coal  <- grepl("coal", NEISCC$Short.Name, ignore.case=TRUE)
subset.NEISCC <- NEISCC[coal, ]
totalByYear <- aggregate(Emissions ~ year, subset.NEISCC, sum)
png("ExData_Plotting2/plot4.png", width=640, height=480)
plt <- ggplot(totalByYear, aes(factor(year), Emissions, fill='red'))
plt <- plt +
geom_bar(stat="identity") +
xlab("year") +
ylab(expression('PM 2.5 emission')) +
theme(legend.position='none') +
ggtitle('Total Emissions from coal (1999 - 2008 by 3 year intervals)')
print(plt)
dev.off()
